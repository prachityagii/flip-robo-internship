{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d5f0a4",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e381328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c483d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n",
    "for i in soup.find_all(header_tags):\n",
    "    print(i.name + ' -> ' + i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94761b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3238af89",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c742450",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls055592025/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a48ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [] \n",
    "\n",
    "for i in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "    x = i.find('a').text\n",
    "    titles.append(x)\n",
    "\n",
    "titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "\n",
    "for i in soup.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "    \n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(titles), len(rating),len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Titles': titles, 'Rating': rating, 'Year of release': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39db43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index +=1\n",
    "df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8acf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7f1bb5",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls009997493/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for i in soup.find_all(\"h3\",class_=\"lister-item-header\"):\n",
    "    x = i.find('a').text\n",
    "    titles.append(x)\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e62414",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff77b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "\n",
    "for i in soup.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "    \n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Titles': titles, 'Rating': rating, 'Year of release': year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index +=1\n",
    "df.index\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22704731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fa411d",
   "metadata": {},
   "source": [
    "# 4) Write a python program to display list of respected former presidents of India(i.e. Name , Term of office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da015ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365eca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = soup.find(\"div\", class_=\"contentWrap bgdWhite cf\")\n",
    "rankings = {}\n",
    "\n",
    "for i in tb.find_all('div', class_=\"presidentListing\"):\n",
    "        name = i.find('h3').text.strip()\n",
    "        term_of_service = i.find(\"p\").text.split(\":\")[1]\n",
    "        \n",
    "        rankings[name] ={'Term of Service': term_of_service,\n",
    "                          }\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127bc2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d122bdd6",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f1d64",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entire table\n",
    "table = soup.find('table',class_='table')\n",
    "\n",
    "# create dictionary to hold results\n",
    "rankings = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = table.find('td', class_='rankings-block__banner--pos').text.strip()\n",
    "country_name = table.find('span', class_='u-hide-phablet').text.strip()\n",
    "matches = table.find('td', class_='rankings-block__banner--matches').text.strip()\n",
    "points = table.find('td', class_='rankings-block__banner--points').text.strip()\n",
    "rating = table.find('td', class_='rankings-block__banner--rating u-text-right').text.strip()\n",
    "rankings[country_name] = {'position': position,\n",
    "                          'matches': matches,\n",
    "                          'points': points,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for row in table.find_all('tr', class_='table-body'):\n",
    "    position = row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    country_name = row.find('span', class_='u-hide-phablet').text.strip()\n",
    "    matches = row.find_all('td', class_='table-body__cell u-center-text')[0].text.strip()\n",
    "    points = row.find_all('td', class_='table-body__cell u-center-text')[1].text.strip()\n",
    "    rating = row.find('td', class_='table-body__cell u-text-right rating').text.strip()\n",
    "    rankings[country_name] = {'position': position,\n",
    "                          'matches': matches,\n",
    "                          'points': points,\n",
    "                          'rating': rating}\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8db2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(rankings)\n",
    "df.iloc[:, : 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a25326",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfadfa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to hold results\n",
    "tb = soup.find(\"div\", class_=\"col-4 col-12-desk touch-scroll-list__element\")\n",
    "rankings = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = soup.find('span', class_=\"rankings-block__pos-number\").text.strip()\n",
    "player_name = soup.find('div', class_=\"rankings-block__banner--name\").text.strip()\n",
    "country = soup.find('div', class_=\"rankings-block__banner--nationality\").text.split('\\n')[2]\n",
    "rating = soup.find('div', class_=\"rankings-block__banner--rating\").text.strip()\n",
    "rankings[player_name] = {'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for i in tb.find_all('tr', class_=\"table-body\"):\n",
    "        position = i.find('span', class_=\"rankings-table__pos-number\").text.strip()\n",
    "        player_name = i.find(\"td\",class_=\"table-body__cell name\").text.strip()\n",
    "        country = i.find(\"span\",class_=\"table-body__logo-text\").text.strip()\n",
    "        rating = i.find(\"td\",class_=\"table-body__cell u-text-right rating\").text.strip()\n",
    "        rankings[player_name] ={'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4a382",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c48ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to hold results\n",
    "tb = soup.find(\"table\", class_=\"table rankings-table\")\n",
    "rankings2 = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = soup.find('span', class_=\"rankings-block__pos-number\").text.strip()\n",
    "player_name = soup.find('div', class_=\"rankings-block__banner--name-large\").text.strip()\n",
    "country = soup.find('div', class_=\"rankings-block__banner--nationality\").text.split('\\n')[2]\n",
    "rating = soup.find('div', class_=\"rankings-block__banner--rating\").text.strip()\n",
    "rankings2[player_name] = {'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for i in tb.find_all('tr', class_=\"table-body\"):\n",
    "        position = i.find('span', class_=\"rankings-table__pos-number\").text.strip()\n",
    "        player_name = i.find(\"td\",class_=\"table-body__cell rankings-table__name name\").text.strip()\n",
    "        country = i.find(\"span\",class_=\"table-body__logo-text\").text.strip()\n",
    "        rating = i.find(\"td\",class_=\"table-body__cell rating\").text.strip()\n",
    "        rankings2[player_name] ={'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "rankings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rankings2)\n",
    "df.iloc[:, : 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b1201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47986ba2",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc83af",
   "metadata": {},
   "source": [
    "# a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea44c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d95948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entire table\n",
    "table = soup.find('table',class_='table')\n",
    "\n",
    "# create dictionary to hold results\n",
    "rankings = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = table.find('td', class_='rankings-block__banner--pos').text.strip()\n",
    "country_name = table.find('span', class_='u-hide-phablet').text.strip()\n",
    "matches = table.find('td', class_='rankings-block__banner--matches').text.strip()\n",
    "points = table.find('td', class_='rankings-block__banner--points').text.strip()\n",
    "rating = table.find('td', class_='rankings-block__banner--rating u-text-right').text.strip()\n",
    "rankings[country_name] = {'position': position,\n",
    "                          'matches': matches,\n",
    "                          'points': points,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for row in table.find_all('tr', class_='table-body'):\n",
    "    position = row.find('td', class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    country_name = row.find('span', class_='u-hide-phablet').text.strip()\n",
    "    matches = row.find_all('td', class_='table-body__cell u-center-text')[0].text.strip()\n",
    "    points = row.find_all('td', class_='table-body__cell u-center-text')[1].text.strip()\n",
    "    rating = row.find('td', class_='table-body__cell u-text-right rating').text.strip()\n",
    "    rankings[country_name] = {'position': position,\n",
    "                          'matches': matches,\n",
    "                          'points': points,\n",
    "                          'rating': rating}\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9cb6f",
   "metadata": {},
   "source": [
    "# b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to hold results\n",
    "tb = soup.find(\"div\", class_=\"col-4 col-12-desk uniform-grid__section touch-scroll-list__element\")\n",
    "rankings = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = soup.find('span', class_=\"rankings-block__pos-number\").text.strip()\n",
    "player_name = soup.find('div', class_=\"rankings-block__banner--name\").text.strip()\n",
    "country = soup.find('div', class_=\"rankings-block__banner--nationality\").text.split('\\n')[2]\n",
    "rating = soup.find('div', class_=\"rankings-block__banner--rating\").text.strip()\n",
    "rankings[player_name] = {'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for i in tb.find_all('tr', class_=\"table-body\"):\n",
    "        position = i.find('span', class_=\"rankings-table__pos-number\").text.strip()\n",
    "        player_name = i.find(\"td\",class_=\"table-body__cell name\").text.strip()\n",
    "        country = i.find(\"span\",class_=\"table-body__logo-text\").text.strip()\n",
    "        rating = i.find(\"td\",class_=\"table-body__cell u-text-right rating\").text.strip()\n",
    "        rankings[player_name] ={'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8235c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fbba70",
   "metadata": {},
   "source": [
    "# c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24409039",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090a196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to hold results\n",
    "tb = soup.find(\"table\", class_=\"table rankings-table\")\n",
    "rankings2 = {}\n",
    "\n",
    "# separate first row since it uses different markup than the rest\n",
    "position = soup.find('span', class_=\"rankings-block__pos-number\").text.strip()\n",
    "player_name = soup.find('div', class_=\"rankings-block__banner--name-large\").text.strip()\n",
    "country = soup.find('div', class_=\"rankings-block__banner--nationality\").text.split('\\n')[2]\n",
    "rating = soup.find('div', class_=\"rankings-block__banner--rating\").text.strip()\n",
    "rankings2[player_name] = {'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "\n",
    "# for the next rows, use a loop\n",
    "for i in tb.find_all('tr', class_=\"table-body\"):\n",
    "        position = i.find('span', class_=\"rankings-table__pos-number\").text.strip()\n",
    "        player_name = i.find(\"td\",class_=\"table-body__cell rankings-table__name name\").text.strip()\n",
    "        country = i.find(\"span\",class_=\"table-body__logo-text\").text.strip()\n",
    "        rating = i.find(\"td\",class_=\"table-body__cell rating\").text.strip()\n",
    "        rankings2[player_name] ={'position': position,\n",
    "                          'country': country,\n",
    "                          'rating': rating}\n",
    "rankings2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1436d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rankings2)\n",
    "df.iloc[:, : 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cd293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dbb38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8bb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2009ddbf",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b053ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3393d",
   "metadata": {},
   "source": [
    "# 1) Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_headline = []\n",
    "for i in soup.find_all(\"a\", class_='LatestNews-headline'):\n",
    "    news_headline.append(i.text)\n",
    "news_headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b9062",
   "metadata": {},
   "source": [
    "# 2) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_time = []\n",
    "for i in soup.find_all(\"span\",class_=\"LatestNews-wrapper\"):\n",
    "    news_time.append(i.text)\n",
    "news_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088fc02",
   "metadata": {},
   "source": [
    "# 3) News link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_link = []\n",
    "for i in soup.find_all(\"a\", class_='LatestNews-headline'):\n",
    "    news_link.append(i.get('href'))\n",
    "news_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e10b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bca3dbd4",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf25e4e",
   "metadata": {},
   "source": [
    "# 1) Paper title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in soup.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110dd9d",
   "metadata": {},
   "source": [
    "# 2) Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for i in soup.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1167837",
   "metadata": {},
   "source": [
    "# 3) Published date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a89dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_date = []\n",
    "for i in soup.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    pub_date.append(i.text)\n",
    "pub_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2d28c",
   "metadata": {},
   "source": [
    "# 4) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955036c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_url = []\n",
    "for i in soup.find_all(\"a\", class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    paper_url.append(i.get('href'))\n",
    "paper_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ee81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(title), len(authors), len(pub_date), len(paper_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a5bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7b8e161",
   "metadata": {},
   "source": [
    "# 9)Write a python program to scrape mentioned details from dineout.co.in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c7aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da36e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc768d7",
   "metadata": {},
   "source": [
    "# 1) Restaurant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e4e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [] \n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):\n",
    "    x = i.find('a').text\n",
    "    titles.append(x)\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d3c70",
   "metadata": {},
   "source": [
    "# 2) Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine = []\n",
    "\n",
    "for i in soup.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text)\n",
    "\n",
    "newlist = []\n",
    "for x in cuisine:\n",
    "    split_results = x.split('|')\n",
    "    newlist.append(split_results[1])\n",
    "newlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916d2f2",
   "metadata": {},
   "source": [
    "# 3) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ff499",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = []\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55ce4e",
   "metadata": {},
   "source": [
    "# 4) Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e82887",
   "metadata": {},
   "source": [
    "# 5) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f0328",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    image.append(i['data-src'])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(titles), len(cuisine), len(loc), len(rating), len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea28917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e842def",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad452fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092b1bf",
   "metadata": {},
   "source": [
    "# 1) Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516248d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = []\n",
    "for i in soup.find_all('td', class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf43739",
   "metadata": {},
   "source": [
    "# 2) Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc226a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "publication = []\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "publication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24250a3",
   "metadata": {},
   "source": [
    "# 3) h5-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568791b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_index = [] \n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_n\"):\n",
    "    x = i.find(class_=\"gs_ibl gsc_mp_anchor\")\n",
    "    h5_index.append(x.text)\n",
    "    \n",
    "res = h5_index[::2]\n",
    "\n",
    "h5_index = res\n",
    "\n",
    "h5_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2d1dd",
   "metadata": {},
   "source": [
    "# 4) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_median = []\n",
    "for i in soup.find_all('span', class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_median.append(i.text)\n",
    "h5_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rank), len(publication), len(h5_index), len(h5_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Rank':rank, 'Publication':publication, 'h5-index':h5_index, 'h5-mean':h5_median})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2a330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
